{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepmeg.utils.params import read_pkl, LFCNNParameters\n",
    "from deepmeg.preprocessing.transforms import one_hot_decoder\n",
    "from deepmeg.data.datasets import EpochsDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple('Data', 'conteptual spatial')\n",
    "\n",
    "\n",
    "def concat_data(data: list[Data]) -> Data:\n",
    "    conceptual = np.concatenate([d.conceptual for d in data])\n",
    "    spatial = np.concatenate([d.spatial for d in data])\n",
    "\n",
    "    return Data(conceptual, spatial)\n",
    "\n",
    "\n",
    "def get_data(results_dir: str, subjects: list[int], project_name: str) -> tuple[Data, Data, np.array, np.array, mne.Info]:\n",
    "    all_data, all_tcs = list(), list()\n",
    "    spatial_filters, spectral_filters, info = None, None, None\n",
    "    for subject in subjects:\n",
    "        data_dir = os.path.join(results_dir, f'sbj_{subject}', project_name)\n",
    "\n",
    "        if not os.path.exists(data_dir):\n",
    "            print(f'sbj {subject}: Data directory does not exist')\n",
    "            continue\n",
    "\n",
    "        params_path = os.path.join(data_dir, 'params.pt')\n",
    "        params = LFCNNParameters.load(params_path)\n",
    "\n",
    "        if spatial_filters is None:\n",
    "            spatial_filters = params.spatial.filters\n",
    "\n",
    "        if spectral_filters is None:\n",
    "            spectral_filters = params.spectral.filters\n",
    "\n",
    "        if info is None:\n",
    "            info = params.info\n",
    "\n",
    "        data_path = os.path.join(data_dir, 'dataset.pt')\n",
    "        data = EpochsDataset.load(data_path)\n",
    "        X, Y = next(iter(torch.utils.data.DataLoader(data, len(data))))\n",
    "        Y = one_hot_decoder(Y) # spatial - 0, conceptual - 1\n",
    "        X = X.numpy()\n",
    "        X = Data(X[Y == 0], X[Y == 1])\n",
    "        tc = params.temporal.time_courses_filtered\n",
    "        tc = Data(tc[Y == 0], tc[Y == 1])\n",
    "        all_data.append(X)\n",
    "        all_tcs.append(tc)\n",
    "\n",
    "    return concat_data(all_data), concat_data(all_tcs), spatial_filters, spectral_filters, info\n",
    "\n",
    "\n",
    "def to_tensor(X: np.array) -> torch.Tensor:\n",
    "    return torch.tensor(X)\n",
    "\n",
    "\n",
    "def to_flatten_tensor(X: np.array) -> torch.Tensor:\n",
    "    X = to_tensor(X)\n",
    "    X = X.permute(1, 0, -1)\n",
    "    return X.reshape(X.shape[0], -1)\n",
    "\n",
    "\n",
    "def get_spatial_patterns(X: np.array, S: np.array, W: np.array, H: np.array) -> np.array:\n",
    "    X_flatten, S_flatten, W, H = to_flatten_tensor(X), to_flatten_tensor(S), to_tensor(W), to_tensor(H)\n",
    "    A = list()\n",
    "    for comp_num in range(len(W)):\n",
    "        X_filt_flatten = torch.zeros_like(X_flatten)\n",
    "\n",
    "        for ch_num in range(len(X)):\n",
    "            X_filt_flatten[ch_num] = torch.nn.functional.conv1d(\n",
    "                torch.unsqueeze(X_flatten[ch_num], 0),\n",
    "                torch.unsqueeze(H[comp_num].detach(), 0),\n",
    "                padding='same'\n",
    "            )\n",
    "\n",
    "        A.append(torch.cov(X_filt_flatten)@W[comp_num])\n",
    "\n",
    "    return torch.squeeze(torch.stack(A, 1))@torch.pinverse(torch.cov(S_flatten))\n",
    "\n",
    "\n",
    "def get_spatial_patterns_diff(X: tuple[np.array, np.array], S: tuple[np.array, np.array], W: np.array, H: np.array) -> np.array:\n",
    "    X_flatten, S_flatten, W, H = (to_flatten_tensor(X[0]), to_flatten_tensor(X[1])),\\\n",
    "        (to_flatten_tensor(S[0]), to_flatten_tensor(S[1])),\\\n",
    "        to_tensor(W), to_tensor(H)\n",
    "\n",
    "    A = list()\n",
    "    for comp_num in range(len(W)):\n",
    "        X_filt_flatten = (torch.zeros_like(X_flatten[0]), torch.zeros_like(X_flatten[1]))\n",
    "\n",
    "        for ch_num in range(len(X)):\n",
    "            for i in range(2):\n",
    "                X_filt_flatten[i][ch_num] = torch.nn.functional.conv1d(\n",
    "                    torch.unsqueeze(X_flatten[i][ch_num], 0),\n",
    "                    torch.unsqueeze(H[comp_num].detach(), 0),\n",
    "                    padding='same'\n",
    "                )\n",
    "\n",
    "        A.append(torch.cov(X_filt_flatten[0] - X_filt_flatten[1])@W[comp_num])\n",
    "\n",
    "    return torch.squeeze(torch.stack(A, 1))@torch.pinverse(torch.cov(S_flatten[0] - S_flatten[1]))\n",
    "\n",
    "\n",
    "def test_sources(\n",
    "    condition1: np.ndarray, # n_epochs, n_times, n_latent\n",
    "    condition2: np.ndarray,\n",
    "    **test_kwargs\n",
    ")-> tuple[np.ndarray, list[tuple[int, int]] | np.ndarray, np.ndarray, np.ndarray]:\n",
    "    test_kwargs.setdefault('n_permutations', 10_000)\n",
    "    test_kwargs.setdefault('threshold', 6)\n",
    "    test_kwargs.setdefault('tail', 1)\n",
    "    test_kwargs.setdefault('out_type', 'mask')\n",
    "\n",
    "    if len(condition1) != len(condition2):\n",
    "        min_len = min(len(condition1), len(condition2))\n",
    "        condition1 = condition1[:min_len]\n",
    "        condition2 = condition2[:min_len]\n",
    "\n",
    "    test_data = list()\n",
    "\n",
    "    for n_latent in range(condition1.shape[-1]):\n",
    "        test_data.append(\n",
    "            mne.stats.permutation_cluster_test(\n",
    "                [condition1[:, :, n_latent], condition2[:, :, n_latent]],\n",
    "                **test_kwargs\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def get_significant_ranges(\n",
    "    T_obs: np.ndarray,\n",
    "    clusters: list[tuple[int, int]],\n",
    "    cluster_p_values: np.ndarray,\n",
    "    H0: np.ndarray\n",
    ") -> tuple[list[tuple[int, int]], np.ndarray]:\n",
    "    ranges = list()\n",
    "    binary = np.zeros_like(T_obs)\n",
    "    for i, c in enumerate(clusters):\n",
    "        c = c[0]\n",
    "\n",
    "        if cluster_p_values[i] <= 0.05:\n",
    "            ranges.append((c.start, c.stop - 1))\n",
    "            binary[c.start : c.stop - 1] = 1\n",
    "\n",
    "    return ranges, binary\n",
    "\n",
    "def get_all_significant_ranges(\n",
    "    tests: list[tuple[\n",
    "        np.ndarray,\n",
    "        list[tuple[int, int]],\n",
    "        np.ndarray,\n",
    "        np.ndarray\n",
    "    ]]\n",
    ") -> tuple[list[list[tuple[int, int]]], np.ndarray]:\n",
    "    all_ranges, all_binary = list(), list()\n",
    "    for test in tests:\n",
    "        ranges, binary = get_significant_ranges(*test)\n",
    "        all_ranges.append(ranges)\n",
    "        all_binary.append(binary)\n",
    "\n",
    "    return all_ranges, np.array(all_binary)\n",
    "\n",
    "\n",
    "ClusterSpatialParams = namedtuple('ClusterSpatialParams', 'condition condition2 diff')\n",
    "\n",
    "\n",
    "def get_patterns_in_ranges(\n",
    "    X: tuple[np.ndarray, np.ndarray], # n epochs, n_times, n_channels\n",
    "    S: tuple[np.ndarray, np.ndarray], # n epochs, n_times, n_latent\n",
    "    W: np.ndarray, # n channels, n_latent\n",
    "    H: np.ndarray,\n",
    "    ranges: list[list[tuple[int, int]]]\n",
    ")-> list[list[ClusterSpatialParams]]:\n",
    "    all_clusters = list()\n",
    "    for n_latent in range(len(ranges)):\n",
    "\n",
    "        component_clusters = list()\n",
    "        for cluster in ranges[n_latent]:\n",
    "            start, end = cluster\n",
    "            X_part = (x[:, start:end] for x in X)\n",
    "            S_part = (s[:, start:end] for s in S)\n",
    "            w = np.expand_dims(W[:, n_latent], 1)\n",
    "            h = np.expand_dims(H[n_latent], 0)\n",
    "            pat1 = get_spatial_patterns(X_part[0], S_part[0], w, h)\n",
    "            pat2 = get_spatial_patterns(X_part[1], S_part[1], w, h)\n",
    "            pat_diff = get_spatial_patterns_diff(X_part, S_part, w, h)\n",
    "            component_clusters.append(\n",
    "                ClusterSpatialParams(\n",
    "                    pat1, pat2, pat_diff\n",
    "                )\n",
    "            )\n",
    "        all_clusters.append(component_clusters)\n",
    "\n",
    "    return all_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_subjects = list(range(1, 16)) + list(range(30, 46))\n",
    "even_testing_subjects = [subject for subject in testing_subjects if not subject%2]\n",
    "odd_testing_subjects = [subject for subject in testing_subjects if subject%2]\n",
    "results_dir = '/data/pt_02648/spatual/RESULTS/'\n",
    "data_even, tc_even, W, H, info = get_data(results_dir, even_testing_subjects, '240823_2groups_training_s_vs_c_lfcnn')\n",
    "data_odd, tc_odd, *_ = get_data(results_dir, odd_testing_subjects, '240823_2groups_training_s_vs_c_lfcnn')\n",
    "test_sp_vs_sp = test_sources(tc_odd.spatial, tc_even.spatial)\n",
    "\n",
    "ranges, masks = get_all_significant_ranges(test_sp_vs_sp)\n",
    "clusters_patterns = get_patterns_in_ranges(\n",
    "    (data_odd.spatial, data_even.spatial),\n",
    "    (tc_odd.spatial, tc_odd.spatial),\n",
    "    W, H\n",
    ")\n",
    "\n",
    "test_sp_vs_con = test_sources(tc_odd.spatial, tc_even.conceptual)\n",
    "test_con_vs_sp = test_sources(tc_odd.conceptual, tc_even.spatial)\n",
    "test_con_vs_con = test_sources(tc_odd.conceptual, tc_even.conceptual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.spatial.filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14, 30, 32, 34, 36, 38, 40, 42, 44]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_testing_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/pt_02648/spatual/RESULTS/sbj03/240823_2groups_training_s_vs_c_lfcnn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = LFCNNParameters.load(os.path.join(path, 'params.pkl'))\n",
    "data = EpochsDataset.load(os.path.join(path, 'dataset.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(iter(torch.utils.data.DataLoader(data, len(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([278, 204, 300]), (278, 8, 300), (204, 8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, params.temporal.time_courses_filtered.shape, params.spatial.filters.shape, params.spectral.filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_spatial_patterns(X.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

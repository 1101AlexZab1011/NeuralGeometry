{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepmeg.utils.params import read_pkl, LFCNNParameters\n",
    "from deepmeg.preprocessing.transforms import one_hot_decoder\n",
    "from deepmeg.data.datasets import EpochsDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import logging\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple('Data', 'conteptual spatial')\n",
    "\n",
    "def concat_data(data: list[Data]) -> Data:\n",
    "    conceptual = np.concatenate([d.conceptual for d in data])\n",
    "    spatial = np.concatenate([d.spatial for d in data])\n",
    "\n",
    "    return Data(conceptual, spatial)\n",
    "\n",
    "def get_data(results_dir: str, subjects: list[int], project_name: str) -> tuple[np.array, np.array]:\n",
    "    all_data, all_tcs = list(), list()\n",
    "    for subject in subjects:\n",
    "        data_dir = os.path.join(results_dir, f'sbj_{subject}', project_name)\n",
    "\n",
    "        if not os.path.exists(data_dir):\n",
    "            print(f'sbj {subject}: Data directory does not exist')\n",
    "            continue\n",
    "\n",
    "        params_path = os.path.join(data_dir, 'params.pt')\n",
    "        params = LFCNNParameters.load(params_path)\n",
    "        data_path = os.path.join(data_dir, 'dataset.pt')\n",
    "        data = EpochsDataset.load(data_path)\n",
    "        X, Y = next(iter(torch.utils.data.DataLoader(data, len(data))))\n",
    "        Y = one_hot_decoder(Y) # spatial - 0, conceptual - 1\n",
    "        X = X.numpy()\n",
    "        X = Data(X[Y == 0], X[Y == 1])\n",
    "        tc = params.temporal.time_courses_filtered\n",
    "        tc = Data(tc[Y == 0], tc[Y == 1])\n",
    "        all_data.append(X)\n",
    "        all_tcs.append(tc)\n",
    "\n",
    "    return concat_data(all_data), concat_data(all_tcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(X: np.array) -> torch.Tensor:\n",
    "    return torch.tensor(X)\n",
    "\n",
    "def to_flatten_tensor(X: np.array) -> torch.Tensor:\n",
    "    X = to_tensor(X)\n",
    "    X = X.permute(1, 0, -1)\n",
    "    return X.reshape(X.shape[0], -1)\n",
    "\n",
    "def get_spatial_patterns(X: np.array, S: np.array, W: np.array, H: np.array) -> np.array:\n",
    "    X_flatten, S_flatten, W, H = to_flatten_tensor(X), to_flatten_tensor(S), to_tensor(W), to_tensor(H)\n",
    "    A = list()\n",
    "    for comp_num in range(len(W)):\n",
    "        X_filt_flatten = torch.zeros_like(X_flatten)\n",
    "\n",
    "        for ch_num in range(len(X)):\n",
    "            X_filt_flatten[ch_num] = torch.nn.functional.conv1d(\n",
    "                torch.unsqueeze(X_flatten[ch_num], 0),\n",
    "                torch.unsqueeze(H[comp_num].detach(), 0),\n",
    "                padding='same'\n",
    "            )\n",
    "\n",
    "        A.append(torch.cov(X_filt_flatten)@W[comp_num])\n",
    "\n",
    "    return torch.squeeze(torch.stack(A, 1))@torch.pinverse(torch.cov(S_flatten))\n",
    "\n",
    "def get_spatial_patterns_dif(X: tuple[np.array, np.array], S: [np.array, np.array], W: np.array, H: np.array) -> np.array:\n",
    "    X_flatten, S_flatten, W, H = (to_flatten_tensor(X[0]), to_flatten_tensor(X[1])),\\\n",
    "        (to_flatten_tensor(S[0]), to_flatten_tensor(S[1])),\\\n",
    "        to_tensor(W), to_tensor(H)\n",
    "\n",
    "    A = list()\n",
    "    for comp_num in range(len(W)):\n",
    "        X_filt_flatten = (torch.zeros_like(X_flatten[0]), torch.zeros_like(X_flatten[1]))\n",
    "\n",
    "        for ch_num in range(len(X)):\n",
    "            for i in range(2):\n",
    "                X_filt_flatten[i][ch_num] = torch.nn.functional.conv1d(\n",
    "                    torch.unsqueeze(X_flatten[i][ch_num], 0),\n",
    "                    torch.unsqueeze(H[comp_num].detach(), 0),\n",
    "                    padding='same'\n",
    "                )\n",
    "\n",
    "        A.append(torch.cov(X_filt_flatten[0] - X_filt_flatten[1])@W[comp_num])\n",
    "\n",
    "    return torch.squeeze(torch.stack(A, 1))@torch.pinverse(torch.cov(S_flatten[0] - S_flatten[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.67151116, -0.02376611],\n",
       "       [-0.02376611,  2.17065662]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.randn(2, 100)\n",
    "Y = np.random.randn(2, 100)\n",
    "np.cov(X - Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30188234,  0.05748509],\n",
       "       [ 0.05748509, -0.01469686]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X) - np.cov(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2), (4, 4), (2, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X).shape, np.cov(X, Y).shape, np.cov(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0727, 0.1351],\n",
       "        [0.1351, 1.0073]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cov(torch.tensor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_subjects = list(range(1, 16)) + list(range(30, 46))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/pt_02648/spatual/RESULTS/sbj03/240823_2groups_training_s_vs_c_lfcnn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = LFCNNParameters.load(os.path.join(path, 'params.pkl'))\n",
    "data = EpochsDataset.load(os.path.join(path, 'dataset.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(iter(torch.utils.data.DataLoader(data, len(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_decoder(Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14153191,  0.04649969, -0.15692748, ...,  0.03119358,\n",
       "        -0.0477738 , -0.10818242],\n",
       "       [ 0.0890969 , -0.14958961,  0.1622523 , ..., -0.07839492,\n",
       "        -0.15980974, -0.00503751],\n",
       "       [-0.0675671 , -0.01350878, -0.08116332, ...,  0.04573811,\n",
       "        -0.02252196, -0.02341661],\n",
       "       ...,\n",
       "       [ 0.00175935,  0.02097855, -0.04889872, ...,  0.15193492,\n",
       "        -0.07784075, -0.01948833],\n",
       "       [ 0.03758526,  0.05434806, -0.15772349, ...,  0.00901611,\n",
       "         0.05456335, -0.01826791],\n",
       "       [ 0.00937487,  0.14295019, -0.13633385, ..., -0.0538195 ,\n",
       "         0.04105514,  0.04743095]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params.spatial.filters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
